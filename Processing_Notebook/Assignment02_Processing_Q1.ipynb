{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark notebook ###\n",
    "\n",
    "This notebook will only work in a Jupyter session running on `mathmadslinux2p`.\n",
    "\n",
    "You can start your own Jupyter session on `mathmadslinux2p` and open this notebook in Chrome on the MADS Windows server by\n",
    "\n",
    "**Steps**\n",
    "\n",
    "1. Login to the MADS Windows server using https://mathportal.canterbury.ac.nz/.\n",
    "2. Download or copy this notebook to your home directory.\n",
    "3. Open powershell and run `ssh mathmadslinux2p`.\n",
    "4. Run `start_pyspark_notebook` or `/opt/anaconda3/bin/jupyter-notebook --ip 132.181.129.68 --port $((8000 + $((RANDOM % 999))))`.\n",
    "5. Copy / paste the url provided in the shell window into Chrome on the MADS Windows server.\n",
    "6. Open the notebook from the Jupyter root directory (which is your home directory).\n",
    "7. Run `start_spark()` to start a spark session in the notebook.\n",
    "8. Run `stop_spark()` before closing the notebook or kill your spark application by hand using the link in the Spark UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }table.dataframe td { white-space: nowrap !important; }table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to import pyspark and to define start_spark() and stop_spark()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import random\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Functions used below\n",
    "\n",
    "def username():\n",
    "    \"\"\"Get username with any domain information removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return re.sub('@.*', '', getpass.getuser())\n",
    "\n",
    "\n",
    "def dict_to_html(d):\n",
    "    \"\"\"Convert a Python dictionary into a two column table for display.\n",
    "    \"\"\"\n",
    "\n",
    "    html = []\n",
    "\n",
    "    html.append(f'<table width=\"100%\" style=\"width:100%; font-family: monospace;\">')\n",
    "    for k, v in d.items():\n",
    "        html.append(f'<tr><td style=\"text-align:left;\">{k}</td><td>{v}</td></tr>')\n",
    "    html.append(f'</table>')\n",
    "\n",
    "    return ''.join(html)\n",
    "\n",
    "\n",
    "def show_as_html(df, n=10):\n",
    "    \"\"\"Leverage existing pandas jupyter integration to show a spark dataframe as html.\n",
    "    \n",
    "    Args:\n",
    "        n (int): number of rows to show (default: 20)\n",
    "    \"\"\"\n",
    "\n",
    "    display(df.limit(n).toPandas())\n",
    "\n",
    "    \n",
    "def display_spark():\n",
    "    \"\"\"Display the status of the active Spark session if one is currently running.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        name = sc.getConf().get(\"spark.app.name\")\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>{name}</code> under the running applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'<li><a href=\"{sc.uiWebUrl}\" target=\"_blank\">Spark Application UI</a></li>',\n",
    "            f'</ul>',\n",
    "            f'<p><b>Config</b></p>',\n",
    "            dict_to_html(dict(sc.getConf().getAll())),\n",
    "            f'<p><b>Notes</b></p>',\n",
    "            f'<ul>',\n",
    "            f'<li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li>',\n",
    "            f'<li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>{name}</code> by hand using the link in the Spark UI.</li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:red\">stopped</span></b>, confirm that <code>{username() + \" (jupyter)\"}</code> is under the completed applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "\n",
    "\n",
    "# Functions to start and stop spark\n",
    "\n",
    "def start_spark(executor_instances=2, executor_cores=1, worker_memory=1, master_memory=1):\n",
    "    \"\"\"Start a new Spark session and define globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \n",
    "    Args:\n",
    "        executor_instances (int): number of executors (default: 2)\n",
    "        executor_cores (int): number of cores per executor (default: 1)\n",
    "        worker_memory (float): worker memory (default: 1)\n",
    "        master_memory (float): master memory (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    user = username()\n",
    "    \n",
    "    cores = executor_instances * executor_cores\n",
    "    partitions = cores * 4\n",
    "    port = 4000 + random.randint(1, 999)\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .master(\"spark://masternode2:7077\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dderby.system.home=/tmp/{user}/spark/\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "        .config(\"spark.executor.instances\", str(executor_instances))\n",
    "        .config(\"spark.executor.cores\", str(executor_cores))\n",
    "        .config(\"spark.cores.max\", str(cores))\n",
    "        .config(\"spark.executor.memory\", f\"{worker_memory}g\")\n",
    "        .config(\"spark.driver.memory\", f\"{master_memory}g\")\n",
    "        .config(\"spark.driver.maxResultSize\", \"0\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", str(partitions))\n",
    "        .config(\"spark.ui.port\", str(port))\n",
    "        .appName(user + \" (jupyter)\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    \n",
    "    display_spark()\n",
    "\n",
    "    \n",
    "def stop_spark():\n",
    "    \"\"\"Stop the active Spark session and delete globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        spark.stop()\n",
    "\n",
    "        del spark\n",
    "        del sc\n",
    "\n",
    "    display_spark()\n",
    "\n",
    "\n",
    "# Make css changes to improve spark output readability\n",
    "\n",
    "html = [\n",
    "    '<style>',\n",
    "    'pre { white-space: pre !important; }',\n",
    "    'table.dataframe td { white-space: nowrap !important; }',\n",
    "    'table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }',\n",
    "    '</style>',\n",
    "]\n",
    "display(HTML(''.join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>Spark</b></p><p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>kda115 (jupyter)</code> under the running applications section in the Spark UI.</p><ul><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:4728\" target=\"_blank\">Spark Application UI</a></li></ul><p><b>Config</b></p><table width=\"100%\" style=\"width:100%; font-family: monospace;\"><tr><td style=\"text-align:left;\">spark.app.name</td><td>kda115 (jupyter)</td></tr><tr><td style=\"text-align:left;\">spark.dynamicAllocation.enabled</td><td>false</td></tr><tr><td style=\"text-align:left;\">spark.executor.instances</td><td>4</td></tr><tr><td style=\"text-align:left;\">spark.driver.memory</td><td>4g</td></tr><tr><td style=\"text-align:left;\">spark.executor.memory</td><td>4g</td></tr><tr><td style=\"text-align:left;\">spark.master</td><td>spark://masternode2:7077</td></tr><tr><td style=\"text-align:left;\">spark.executor.id</td><td>driver</td></tr><tr><td style=\"text-align:left;\">spark.executor.cores</td><td>2</td></tr><tr><td style=\"text-align:left;\">spark.app.startTime</td><td>1726969158275</td></tr><tr><td style=\"text-align:left;\">spark.driver.host</td><td>mathmadslinux2p.canterbury.ac.nz</td></tr><tr><td style=\"text-align:left;\">spark.driver.port</td><td>44141</td></tr><tr><td style=\"text-align:left;\">spark.sql.shuffle.partitions</td><td>32</td></tr><tr><td style=\"text-align:left;\">spark.rdd.compress</td><td>True</td></tr><tr><td style=\"text-align:left;\">spark.serializer.objectStreamReset</td><td>100</td></tr><tr><td style=\"text-align:left;\">spark.driver.maxResultSize</td><td>0</td></tr><tr><td style=\"text-align:left;\">spark.ui.port</td><td>4728</td></tr><tr><td style=\"text-align:left;\">spark.cores.max</td><td>8</td></tr><tr><td style=\"text-align:left;\">spark.submit.pyFiles</td><td></td></tr><tr><td style=\"text-align:left;\">spark.submit.deployMode</td><td>client</td></tr><tr><td style=\"text-align:left;\">spark.driver.extraJavaOptions</td><td>-Dderby.system.home=/tmp/kda115/spark/</td></tr><tr><td style=\"text-align:left;\">spark.ui.showConsoleProgress</td><td>true</td></tr><tr><td style=\"text-align:left;\">spark.app.id</td><td>app-20240922133919-1247</td></tr><tr><td style=\"text-align:left;\">spark.sql.warehouse.dir</td><td>file:/users/home/kda115/Assignment%2002/Assignment_Notebook/spark-warehouse</td></tr></table><p><b>Notes</b></p><ul><li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li><li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>kda115 (jupyter)</code> by hand using the link in the Spark UI.</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to start a spark session in this notebook\n",
    "\n",
    "start_spark(executor_instances=4, executor_cores=2, worker_memory=4, master_memory=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your imports and code here or insert cells below\n",
    "\n",
    "from pyspark.sql import Row, DataFrame, Window, functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Give an overview of the structure of the datasets, including their sizes, formats, data types, and how each dataset has been stored in HDFS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. List the files in the HDFS directory to understand the dataset's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "drwxr-xr-x   - jsw93 supergroup          0 2021-09-29 10:35 hdfs:///data/msd/audio\n",
      "drwxr-xr-x   - jsw93 supergroup          0 2021-09-29 10:35 hdfs:///data/msd/genre\n",
      "drwxr-xr-x   - jsw93 supergroup          0 2021-09-29 10:28 hdfs:///data/msd/main\n",
      "drwxr-xr-x   - jsw93 supergroup          0 2021-09-29 10:35 hdfs:///data/msd/tasteprofile\n"
     ]
    }
   ],
   "source": [
    "# Listing the contents of the HDFS directory\n",
    "! hdfs dfs -ls hdfs:///data/msd/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the sizes of each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Get the overall size of each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3 G   98.1 G   hdfs:///data/msd/audio\r\n",
      "30.1 M   241.0 M  hdfs:///data/msd/genre\r\n",
      "174.4 M  1.4 G    hdfs:///data/msd/main\r\n",
      "490.4 M  3.8 G    hdfs:///data/msd/tasteprofile\r\n"
     ]
    }
   ],
   "source": [
    "# Get the size of each file in the dataset\n",
    "! hdfs dfs -du -h hdfs:///data/msd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.9 G  103.5 G  hdfs:///data/msd\r\n"
     ]
    }
   ],
   "source": [
    "# using -du and -s provide a summary of disk usage for the entire directory\n",
    "! hdfs dfs -du -s -h hdfs:///data/msd/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  Explore file size of  Audio directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3 G  98.1 G  /data/msd/audio\n",
      "103.0 K  824.3 K  /data/msd/audio/attributes\n",
      "12.2 G   97.8 G   /data/msd/audio/features\n",
      "40.3 M   322.1 M  /data/msd/audio/statistics\n"
     ]
    }
   ],
   "source": [
    "# Displays file sizes and directory of Audio dataset \n",
    "! hdfs dfs -du -s -h /data/msd/audio\n",
    "# Get the size of audio file in the dataset\n",
    "! hdfs dfs -du -h /data/msd/audio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.0 K  824.3 K  /data/msd/audio/attributes\n",
      "1.0 K   8.2 K    /data/msd/audio/attributes/msd-jmir-area-of-moments-all-v1.0.attributes.csv\n",
      "671     5.2 K    /data/msd/audio/attributes/msd-jmir-lpc-all-v1.0.attributes.csv\n",
      "484     3.8 K    /data/msd/audio/attributes/msd-jmir-methods-of-moments-all-v1.0.attributes.csv\n",
      "898     7.0 K    /data/msd/audio/attributes/msd-jmir-mfcc-all-v1.0.attributes.csv\n",
      "777     6.1 K    /data/msd/audio/attributes/msd-jmir-spectral-all-all-v1.0.attributes.csv\n",
      "777     6.1 K    /data/msd/audio/attributes/msd-jmir-spectral-derivatives-all-all-v1.0.attributes.csv\n",
      "12.0 K  96.2 K   /data/msd/audio/attributes/msd-marsyas-timbral-v1.0.attributes.csv\n",
      "9.8 K   78.0 K   /data/msd/audio/attributes/msd-mvd-v1.0.attributes.csv\n",
      "1.4 K   10.9 K   /data/msd/audio/attributes/msd-rh-v1.0.attributes.csv\n",
      "34.1 K  272.8 K  /data/msd/audio/attributes/msd-rp-v1.0.attributes.csv\n",
      "3.8 K   30.8 K   /data/msd/audio/attributes/msd-ssd-v1.0.attributes.csv\n",
      "9.8 K   78.0 K   /data/msd/audio/attributes/msd-trh-v1.0.attributes.csv\n",
      "27.6 K  221.2 K  /data/msd/audio/attributes/msd-tssd-v1.0.attributes.csv\n"
     ]
    }
   ],
   "source": [
    "# File size and directory contained in attributes subdirectory\n",
    "! hdfs dfs -du -s -h /data/msd/audio/attributes\n",
    "\n",
    "# Displays sizes attributes subdirectory\n",
    "\n",
    "! hdfs dfs -du -h /data/msd/audio/attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2 G  97.8 G  /data/msd/audio/features\n",
      "65.5 M   524.2 M  /data/msd/audio/features/msd-jmir-area-of-moments-all-v1.0.csv\n",
      "53.1 M   424.6 M  /data/msd/audio/features/msd-jmir-lpc-all-v1.0.csv\n",
      "35.8 M   286.5 M  /data/msd/audio/features/msd-jmir-methods-of-moments-all-v1.0.csv\n",
      "70.8 M   566.1 M  /data/msd/audio/features/msd-jmir-mfcc-all-v1.0.csv\n",
      "51.1 M   408.9 M  /data/msd/audio/features/msd-jmir-spectral-all-all-v1.0.csv\n",
      "51.1 M   408.9 M  /data/msd/audio/features/msd-jmir-spectral-derivatives-all-all-v1.0.csv\n",
      "412.2 M  3.2 G    /data/msd/audio/features/msd-marsyas-timbral-v1.0.csv\n",
      "1.3 G    10.3 G   /data/msd/audio/features/msd-mvd-v1.0.csv\n",
      "240.3 M  1.9 G    /data/msd/audio/features/msd-rh-v1.0.csv\n",
      "4.0 G    32.3 G   /data/msd/audio/features/msd-rp-v1.0.csv\n",
      "640.6 M  5.0 G    /data/msd/audio/features/msd-ssd-v1.0.csv\n",
      "1.4 G    11.5 G   /data/msd/audio/features/msd-trh-v1.0.csv\n",
      "3.9 G    31.0 G   /data/msd/audio/features/msd-tssd-v1.0.csv\n"
     ]
    }
   ],
   "source": [
    "# File size and directory contained in features subdirectory\n",
    "! hdfs dfs -du -s -h /data/msd/audio/features\n",
    "\n",
    "# Displays sizes features subdirectory\n",
    "\n",
    "! hdfs dfs -du -h /data/msd/audio/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.3 M  322.1 M  /data/msd/audio/statistics\n",
      "40.3 M  322.1 M  /data/msd/audio/statistics/sample_properties.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# File size and directory contained in statistics subdirectory\n",
    "! hdfs dfs -du -s -h /data/msd/audio/statistics\n",
    "\n",
    "# Displays sizes statistics subdirectory\n",
    "\n",
    "! hdfs dfs -du -h /data/msd/audio/statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |-----attributes\n",
      " |-------msd-jmir-area-of-moments-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-lpc-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-methods-of-moments-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-mfcc-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-spectral-all-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-spectral-derivatives-all-all-v1.0.attributes.csv\n",
      " |-------msd-marsyas-timbral-v1.0.attributes.csv\n",
      " |-------msd-mvd-v1.0.attributes.csv\n",
      " |-------msd-rh-v1.0.attributes.csv\n",
      " |-------msd-rp-v1.0.attributes.csv\n",
      " |-------msd-ssd-v1.0.attributes.csv\n",
      " |-------msd-trh-v1.0.attributes.csv\n",
      " |-------msd-tssd-v1.0.attributes.csv\n",
      " |-----features\n",
      " |-------msd-jmir-area-of-moments-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-lpc-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-methods-of-moments-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-mfcc-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-spectral-all-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-spectral-derivatives-all-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-marsyas-timbral-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-mvd-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-rh-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-rp-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-ssd-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-trh-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-tssd-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-----statistics\n",
      " |-------sample_properties.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# Directory trees of Audio dataset\n",
    "! hdfs dfs -ls -R /data/msd/audio | awk '{print $8}' | sed -e 's/[^-][^\\/]*\\//--/g' -e 's/^/ /' -e 's/-/|/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explore file size genre directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.1 M  241.0 M  /data/msd/genre\n",
      "11.1 M  88.7 M  /data/msd/genre/msd-MAGD-genreAssignment.tsv\n",
      "8.4 M   67.3 M  /data/msd/genre/msd-MASD-styleAssignment.tsv\n",
      "10.6 M  85.0 M  /data/msd/genre/msd-topMAGD-genreAssignment.tsv\n"
     ]
    }
   ],
   "source": [
    "# Get the size of genre file in the dataset\n",
    "! hdfs dfs -du -s -h /data/msd/genre\n",
    "\n",
    "# Get the file seze of genre subdirectory \n",
    "! hdfs dfs -du -h /data/msd/genre/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |-----msd-MAGD-genreAssignment.tsv\r\n",
      " |-----msd-MASD-styleAssignment.tsv\r\n",
      " |-----msd-topMAGD-genreAssignment.tsv\r\n"
     ]
    }
   ],
   "source": [
    "# Directory trees of Genre directory\n",
    "! hdfs dfs -ls -R /data/msd/genre | awk '{print $8}' | sed -e 's/[^-][^\\/]*\\//--/g' -e 's/^/ /' -e 's/-/|/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Explore file size of Main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.4 M  1.4 G  /data/msd/main\n",
      "55.9 M   447.5 M  /data/msd/main/summary/analysis.csv.gz\n",
      "118.5 M  947.7 M  /data/msd/main/summary/metadata.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the size of Main file in the dataset\n",
    "! hdfs dfs -du -s -h /data/msd/main\n",
    "\n",
    "# Get the file seze of main subdirectory \n",
    "! hdfs dfs -du -h /data/msd/main/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |-----summary\r\n",
      " |-------analysis.csv.gz\r\n",
      " |-------metadata.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "# Directory trees of Main directory\n",
    "! hdfs dfs -ls -R /data/msd/main | awk '{print $8}' | sed -e 's/[^-][^\\/]*\\//--/g' -e 's/^/ /' -e 's/-/|/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Explore file size of Tasteprofile directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490.4 M  3.8 G  /data/msd/tasteprofile\n",
      "2.0 M    16.2 M  /data/msd/tasteprofile/mismatches\n",
      "488.4 M  3.8 G   /data/msd/tasteprofile/triplets.tsv\n"
     ]
    }
   ],
   "source": [
    "# Get the size of Tasteprofile file in the directory\n",
    "! hdfs dfs -du -s -h /data/msd/tasteprofile\n",
    "\n",
    "# Get the file size of Tasteprofile subdirectory \n",
    "! hdfs dfs -du -h /data/msd/tasteprofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 M  16.2 M  /data/msd/tasteprofile/mismatches\n",
      "89.2 K  713.6 K  /data/msd/tasteprofile/mismatches/sid_matches_manually_accepted.txt\n",
      "1.9 M   15.5 M   /data/msd/tasteprofile/mismatches/sid_mismatches.txt\n"
     ]
    }
   ],
   "source": [
    "# Get the size of mismatches file in the Tasteprofile directory\n",
    "! hdfs dfs -du -s -h /data/msd/tasteprofile/mismatches\n",
    "\n",
    "# Get the file size of file contain in mismatches subdirectory \n",
    "! hdfs dfs -du -h /data/msd/tasteprofile/mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |-----mismatches\r\n",
      " |-------sid_matches_manually_accepted.txt\r\n",
      " |-------sid_mismatches.txt\r\n",
      " |-----triplets.tsv\r\n",
      " |-------part-00000.tsv.gz\r\n",
      " |-------part-00001.tsv.gz\r\n",
      " |-------part-00002.tsv.gz\r\n",
      " |-------part-00003.tsv.gz\r\n",
      " |-------part-00004.tsv.gz\r\n",
      " |-------part-00005.tsv.gz\r\n",
      " |-------part-00006.tsv.gz\r\n",
      " |-------part-00007.tsv.gz\r\n"
     ]
    }
   ],
   "source": [
    "# Directory trees of Tasteprofile directory\n",
    "! hdfs dfs -ls -R /data/msd/tasteprofile | awk '{print $8}' | sed -e 's/[^-][^\\/]*\\//--/g' -e 's/^/ /' -e 's/-/|/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |---audio\n",
      " |-----attributes\n",
      " |-------msd-jmir-area-of-moments-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-lpc-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-methods-of-moments-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-mfcc-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-spectral-all-all-v1.0.attributes.csv\n",
      " |-------msd-jmir-spectral-derivatives-all-all-v1.0.attributes.csv\n",
      " |-------msd-marsyas-timbral-v1.0.attributes.csv\n",
      " |-------msd-mvd-v1.0.attributes.csv\n",
      " |-------msd-rh-v1.0.attributes.csv\n",
      " |-------msd-rp-v1.0.attributes.csv\n",
      " |-------msd-ssd-v1.0.attributes.csv\n",
      " |-------msd-trh-v1.0.attributes.csv\n",
      " |-------msd-tssd-v1.0.attributes.csv\n",
      " |-----features\n",
      " |-------msd-jmir-area-of-moments-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-lpc-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-methods-of-moments-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-mfcc-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-spectral-all-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-jmir-spectral-derivatives-all-all-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-marsyas-timbral-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-mvd-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-rh-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-rp-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-ssd-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-trh-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-------msd-tssd-v1.0.csv\n",
      " |---------part-00000.csv.gz\n",
      " |---------part-00001.csv.gz\n",
      " |---------part-00002.csv.gz\n",
      " |---------part-00003.csv.gz\n",
      " |---------part-00004.csv.gz\n",
      " |---------part-00005.csv.gz\n",
      " |---------part-00006.csv.gz\n",
      " |---------part-00007.csv.gz\n",
      " |-----statistics\n",
      " |-------sample_properties.csv.gz\n",
      " |---genre\n",
      " |-----msd-MAGD-genreAssignment.tsv\n",
      " |-----msd-MASD-styleAssignment.tsv\n",
      " |-----msd-topMAGD-genreAssignment.tsv\n",
      " |---main\n",
      " |-----summary\n",
      " |-------analysis.csv.gz\n",
      " |-------metadata.csv.gz\n",
      " |---tasteprofile\n",
      " |-----mismatches\n",
      " |-------sid_matches_manually_accepted.txt\n",
      " |-------sid_mismatches.txt\n",
      " |-----triplets.tsv\n",
      " |-------part-00000.tsv.gz\n",
      " |-------part-00001.tsv.gz\n",
      " |-------part-00002.tsv.gz\n",
      " |-------part-00003.tsv.gz\n",
      " |-------part-00004.tsv.gz\n",
      " |-------part-00005.tsv.gz\n",
      " |-------part-00006.tsv.gz\n",
      " |-------part-00007.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "# The structure of all Million Songs Dataset (MSD)\n",
    "! hdfs dfs -ls -R /data/msd/ | awk '{print $8}' | sed -e 's/[^-][^\\/]*\\//--/g' -e 's/^/ /' -e 's/-/|/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Figure out how to load each of the different types of datasets, even if you infer schema and only load a small subset of the data for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Loading the  Attributes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area_Method_of_Moments_Overall_Standard_Deviation_1,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_2,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_3,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_4,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_5,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_6,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_7,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_8,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_9,real\r\n",
      "Area_Method_of_Moments_Overall_Standard_Deviation_10,real\r\n"
     ]
    }
   ],
   "source": [
    "# Load the small sample attribute feature dataset using HDFS command\n",
    "! hdfs dfs -cat /data/msd/audio/attributes/msd-jmir-area-of-moments-all-v1.0.attributes.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Loading the  Features Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.431,6713.0,52600.0,160600000.0,1264000000.0,9943000000.0,7.086e+12,11400000000.0,89730000000.0,3.465e+15,5.252,11580.0,90080.0,-179100000.0,-1396000000.0,-10870000000.0,6.236e+12,12580000000.0,98020000000.0,2.97e+15,'TRMMMYQ128F932D901'\r\n",
      "0.9864,3361.0,24270.0,40110000.0,287800000.0,2064000000.0,8.837e+11,2596000000.0,18630000000.0,3.232e+14,2.773,5774.0,41490.0,-44600000.0,-320900000.0,-2307000000.0,7.756e+11,2885000000.0,20760000000.0,2.883e+14,'TRMMMKD128F425225D'\r\n",
      "1.791,6717.0,57790.0,160900000.0,1385000000.0,11910000000.0,7.105e+12,12520000000.0,1.077e+11,4.52e+15,6.43,11600.0,99690.0,-179500000.0,-1544000000.0,-13270000000.0,6.255e+12,13950000000.0,1.2e+11,3.976e+15,'TRMMMRX128F93187D9'\r\n",
      "2.209,3371.0,34750.0,40350000.0,412300000.0,4210000000.0,8.912e+11,3710000000.0,37900000000.0,9.415e+14,5.734,5792.0,58320.0,-44870000.0,-454600000.0,-4603000000.0,7.828e+11,4083000000.0,41370000000.0,8.199e+14,'TRMMMCH128F425532C'\r\n",
      "0.6846,6708.0,30690.0,160400000.0,748900000.0,3492000000.0,7.073e+12,6726000000.0,31380000000.0,7.235e+14,2.485,11580.0,56090.0,-179000000.0,-854900000.0,-4083000000.0,6.227e+12,7670000000.0,36660000000.0,6.654e+14,'TRMMMWA128F426B589'\r\n",
      "0.2944,3355.0,10780.0,39860000.0,130200000.0,424700000.0,8.751e+11,1159000000.0,3786000000.0,3.047e+13,0.4853,5745.0,19090.0,-44210000.0,-145700000.0,-479700000.0,7.663e+11,1291000000.0,4254000000.0,2.718e+13,'TRMMMXN128F42936A5'\r\n",
      "1.634,6718.0,46780.0,160900000.0,1126000000.0,7870000000.0,7.106e+12,10060000000.0,70350000000.0,2.436e+15,5.212,11600.0,79840.0,-179500000.0,-1240000000.0,-8555000000.0,6.256e+12,11060000000.0,76400000000.0,2.078e+15,'TRMMMLR128F1494097'\r\n",
      "1.007,3359.0,22500.0,40040000.0,266200000.0,1769000000.0,8.813e+11,2367000000.0,15740000000.0,2.558e+14,2.634,5770.0,38150.0,-44530000.0,-295500000.0,-1959000000.0,7.738e+11,2622000000.0,17400000000.0,2.265e+14,'TRMMMBB12903CB7D21'\r\n",
      "1.309,6735.0,35260.0,161600000.0,854800000.0,4518000000.0,7.153e+12,7702000000.0,40720000000.0,1.062e+15,2.559,11620.0,61960.0,-180300000.0,-957200000.0,-5077000000.0,6.297e+12,8620000000.0,45750000000.0,9.372e+14,'TRMMMHY12903CB53F1'\r\n",
      "0.5483,3355.0,18410.0,40140000.0,222400000.0,1231000000.0,8.851e+11,1993000000.0,11040000000.0,1.508e+14,0.7773,5794.0,31300.0,-44780000.0,-242800000.0,-1316000000.0,7.793e+11,2173000000.0,11790000000.0,1.262e+14,'TRMMMML128F4280EE9'\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "# Load the small sample feature dataset using HDFS command\n",
    "! hdfs dfs -cat /data/msd/audio/features/msd-jmir-area-of-moments-all-v1.0.csv/part-00000.csv.gz | gunzip | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Loading the Statistic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id,title,artist_name,duration,7digita_Id,sample_bitrate,sample_length,sample_rate,sample_mode,sample_version,filesize\r\n",
      "TRMMMYQ128F932D901,\"Silent Night\",\"Faster Pussy cat\",252.05506,7032331,128,60.1935770567,22050,1,2,960887\r\n",
      "TRMMMKD128F425225D,\"Tanssi vaan\",Karkkiautomaatti,156.55138,1514808,64,30.2244270016,22050,1,2,242038\r\n",
      "TRMMMRX128F93187D9,\"No One Could Ever\",\"Hudson Mohawke\",138.97098,6945353,128,60.1935770567,22050,1,2,960887\r\n",
      "TRMMMCH128F425532C,\"Si Vos Querés\",\"Yerba Brava\",145.05751,2168257,64,30.2083516484,22050,1,2,240534\r\n",
      "TRMMMWA128F426B589,\"Tangle Of Aspens\",\"Der Mystic\",514.29832,2264873,64,60.3382103611,22050,1,2,480443\r\n",
      "TRMMMXN128F42936A5,\"Symphony No. 1 G minor \"\"Sinfonie Serieuse\"\"/Allegro con energia\",\"David Montgomery\",816.53506,3360982,128,30.1360348456,44100,0,1,481070\r\n",
      "TRMMMLR128F1494097,\"We Have Got Love\",\"Sasha / Turbulence\",212.37506,552626,64,60.3542857143,22050,1,2,480686\r\n",
      "TRMMMBB12903CB7D21,\"2 Da Beat Ch'yall\",\"Kris Kross\",221.20444,6435649,128,30.1360348456,44100,0,1,481070\r\n",
      "TRMMMHY12903CB53F1,Goodbye,\"Joseph Locke\",139.17995,8376489,128,60.2459472422,22050,1,2,961723\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "# Load the small sample attribute statistic dataset using HDFS command\n",
    "! hdfs dfs -cat /data/msd/audio/statistics/sample_properties.csv.gz | gunzip | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Loading the Genre Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAAAAK128F9318786\tPop_Rock\r\n",
      "TRAAAAV128F421A322\tPop_Rock\r\n",
      "TRAAAAW128F429D538\tRap\r\n",
      "TRAAABD128F429CF47\tPop_Rock\r\n",
      "TRAAACV128F423E09E\tPop_Rock\r\n",
      "TRAAADT12903CCC339\tEasy_Listening\r\n",
      "TRAAAED128E0783FAB\tVocal\r\n",
      "TRAAAEF128F4273421\tPop_Rock\r\n",
      "TRAAAEM128F93347B9\tElectronic\r\n",
      "TRAAAFD128F92F423A\tPop_Rock\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "# Load the small sample genre dataset using HDFS command\n",
    "! hdfs dfs -cat /data/msd/genre/msd-MAGD-genreAssignment.tsv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 5. Loading the Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzer_version,artist_7digitalid,artist_familiarity,artist_hotttnesss,artist_id,artist_latitude,artist_location,artist_longitude,artist_mbid,artist_name,artist_playmeid,genre,idx_artist_terms,idx_similar_artists,release,release_7digitalid,song_hotttnesss,song_id,title,track_7digitalid\r\n",
      ",4069,0.6498221002008776,0.3940318927141434,ARYZTJS1187B98C555,,,,357ff05d-848a-44cf-b608-cb34b5701ae5,Faster Pussy cat,44895,,0,0,Monster Ballads X-Mas,633681,0.5428987432910862,SOQMMHC12AB0180CB8,Silent Night,7032331\r\n",
      ",113480,0.4396039666767154,0.3569921077564064,ARMVN3U1187FB3A1EB,,,,8d7ef530-a6fd-4f8f-b2e2-74aec765e0f9,Karkkiautomaatti,-1,,0,0,Karkuteillä,145266,0.2998774882739778,SOVFVAK12A8C1350D9,Tanssi vaan,1514808\r\n",
      ",63531,0.6436805720579895,0.4375038365946544,ARGEKB01187FB50750,55.8578,\"Glasgow, Scotland\",-4.24251,3d403d44-36ce-465c-ad43-ae877e65adc4,Hudson Mohawke,-1,,0,0,Butter,625706,0.6178709693948196,SOGTUKN12AB017F4F1,No One Could Ever,6945353\r\n",
      ",65051,0.44850115965646636,0.37234906851712235,ARNWYLR1187B9B2F9C,,,,12be7648-7094-495f-90e6-df4189d68615,Yerba Brava,34000,,0,0,De Culo,199368,,SOBNYVR12A8C13558C,Si Vos Querés,2168257\r\n",
      ",158279,0.0,0.0,AREQDTE1269FB37231,,,,,Der Mystic,-1,,0,0,Rene Ablaze Presents Winter Sessions,209038,,SOHSBXH12A8C13B0DF,Tangle Of Aspens,2264873\r\n",
      ",219281,0.361286979627774,0.10962584705877759,AR2NS5Y1187FB5879D,,,,d087b377-bab7-46c4-bd12-15debebb5d61,David Montgomery,-1,,0,0,Berwald: Symphonies Nos. 1/2/3/4,299244,,SOZVAPQ12A8C13B63C,\"Symphony No. 1 G minor \"\"Sinfonie Serieuse\"\"/Allegro con energia\",3360982\r\n",
      ",3736,0.6929227305760355,0.453731585998959,ARO41T51187FB397AB,,\"Mexico City, Mexico\",,d2461c0a-5575-4425-a225-fce0180de3fd,Sasha / Turbulence,1396,,0,0,Strictly The Best Vol. 34,52968,,SOQVRHI12A6D4FB2D7,We Have Got Love,552626\r\n",
      ",49941,0.5881561876748532,0.40109242517712895,AR3Z9WY1187FB4CDC2,,,,bf61e8ff-7621-4655-8ebd-68210645c5e9,Kris Kross,9594,,0,0,Da Bomb,580432,,SOEYRFT12AB018936C,2 Da Beat Ch'yall,6435649\r\n",
      ",15202,0.4084654634687691,0.28590119604546194,ARA04401187B991E6E,54.99241,\"Londonderry, Northern Ireland\",-7.31923,1a9bf859-1dc2-495b-9e7c-289be7731a9f,Joseph Locke,61524,,0,0,Danny Boy,756677,,SOPMIYT12A6D4F851E,Goodbye,8376489\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "# Load the small sample main dataset using HDFS command\n",
    "! hdfs dfs -cat /data/msd/main/summary/metadata.csv.gz | gunzip | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Loading the Taste Profile Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOAKIMP12A8C130995\t1\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOAPDEY12A81C210A9\t1\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBBMDR12A8C13253B\t2\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBFNSP12AF72A0E22\t1\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBFOVM12A58A7D494\t1\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBNZDC12A6D4FC103\t1\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBSUJE12A6D4F8CF5\t2\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBVFZR12A6D4F8AE3\t1\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBXALG12A8C13C108\t1\r\n",
      "b80344d063b5ccb3212f76538f3d9e43d87dca9e\tSOBXHDL12A81C204C0\t1\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "# Load the small sample TasteProfile triplets dataset using HDFS command\n",
    "! hdfs dfs -cat /data/msd/tasteprofile/triplets.tsv/part-00000.tsv.gz | gunzip | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9d8\r\n",
      "< ERROR: <SOFQHZM12A8C142342 TRMWMFG128F92FFEF2> Josipa Lisac  -  razloga  !=  Lisac Josipa  -  1000 razloga\r\n",
      "19d17\r\n",
      "< ERROR: <SODXUTF12AB018A3DA TRMWPCD12903CCE5ED> Lutan Fyah  -  Nuh Matter the Crisis Feat. Midnite  !=  Midnite  -  Nah Matter the Crisis\r\n",
      "29d26\r\n",
      "< ERROR: <SOASCRF12A8C1372E6 TRMHIPJ128F426A2E2> Gaetano Donizetti  -  L'Elisir d'Amore: Act Two: Come sen va contento!  !=  Gianandrea Gavazzeni_ Orchestra E Coro Del Maggio Musicale Fiorentino_ Carlo Bergonzi_ Renata Scotto  -  L'Elisir D'Amore_ Act 2: Come Sen Va Contento (Adina) (Donizetti)\r\n",
      "33d29\r\n",
      "< ERROR: <SOITDUN12A58A7AACA TRMHXGK128F42446AB> C.J. Chenier  -  Ay, Ai Ai  !=  Clifton Chenier  -  Ay_ Ai Ai\r\n",
      "52d47\r\n",
      "< ERROR: <SOLZXUM12AB018BE39 TRMRSOF12903CCF516> 許志安  -  男人最痛  !=  Andy Hui  -  Nan Ren Zui Tong\r\n",
      "cat: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "# Load the small sample TasteProfile missmatches dataset using HDFS command\n",
    "! hdfs dfs -cat /data/msd/tasteprofile/mismatches/sid_matches_manually_accepted.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Count the number of rows in each of the datasets. How do the counts compare to the total number of unique songs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Counting Rows for the  Attributes Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows for each of file in the attributes and save as csv\n",
    "!for i in `hdfs dfs -ls -R /data/msd/audio/attributes | awk '{print $8}'`; do echo $i ; \\\n",
    "hdfs dfs -cat $i | wc -l; done > attributes_row_num.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows across all files: 3929\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Define the HDFS path for the attributes directory\n",
    "attributes_dir=\"/data/msd/audio/attributes\"\n",
    "\n",
    "# Initialize a variable to store the total row count\n",
    "total_rows=0\n",
    "\n",
    "# Loop through each file in the attributes directory and count the rows (including header)\n",
    "for file in $(hdfs dfs -ls $attributes_dir | awk '{print $8}')\n",
    "do\n",
    "  # Get the number of rows in the current file\n",
    "  row_count=$(hdfs dfs -cat $file | wc -l)\n",
    "  \n",
    "  # Add the row count to the total\n",
    "  total_rows=$((total_rows + row_count))\n",
    "done\n",
    "\n",
    "# Print the total number of rows\n",
    "echo \"Total Row Count for Attribute Directory: $total_rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Counting Rows for the Feature Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: `/data/msd/audio/features/msd-jmir-area-of-moments-all-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-jmir-lpc-all-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-jmir-methods-of-moments-all-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-jmir-mfcc-all-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-jmir-spectral-all-all-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-jmir-spectral-derivatives-all-all-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-marsyas-timbral-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-mvd-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-rh-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-rp-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-ssd-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-trh-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "cat: `/data/msd/audio/features/msd-tssd-v1.0.csv': Is a directory\n",
      "\n",
      "gzip: stdin: unexpected end of file\n"
     ]
    }
   ],
   "source": [
    "# Count the rows for each of file in the features and save as csv\n",
    "!for i in `hdfs dfs -ls -R /data/msd/audio/features | awk '{print $8}'`; do echo $i ; \\\n",
    "hdfs dfs -cat $i | zcat | wc -l; done > features_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Row Count for all Feature Subdirectories: 12927867\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Define the HDFS path for the features directory\n",
    "features_dir=\"/data/msd/audio/features\"\n",
    "\n",
    "# Initialize a variable to store the total row count\n",
    "total_rows=0\n",
    "\n",
    "# Loop through each part file in the features directory and count the rows (including header)\n",
    "for file in $(hdfs dfs -ls -R $features_dir | grep .gz | awk '{print $8}')\n",
    "do\n",
    "  # Get the number of rows in the current compressed part file, and suppress error messages\n",
    "  row_count=$(hdfs dfs -cat $file 2>/dev/null | gunzip | wc -l)\n",
    "  \n",
    "  # Add the row count to the total\n",
    "  total_rows=$((total_rows + row_count))\n",
    "done\n",
    "\n",
    "# Print the total number of rows\n",
    "echo \"Total Row Count for all Feature Subdirectories: $total_rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Counting Rows for the Genre Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows for each of file in the genre and save as csv\n",
    "!for i in `hdfs dfs -ls -R /data/msd/genre | awk '{print $8}'`; do echo $i ; \\\n",
    "hdfs dfs -cat $i | wc -l; done > genre_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /data/msd/genre/msd-MAGD-genreAssignment.tsv, Rows: 422714\n",
      "File: /data/msd/genre/msd-MASD-styleAssignment.tsv, Rows: 273936\n",
      "File: /data/msd/genre/msd-topMAGD-genreAssignment.tsv, Rows: 406427\n",
      "Total Row Count for Genre Directory: 1103077\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Define the HDFS path for the genre directory\n",
    "genre_dir=\"/data/msd/genre\"\n",
    "\n",
    "# Initialize a variable to store the total row count\n",
    "total_rows=0\n",
    "\n",
    "# Loop through each .tsv file in the genre directory and count the rows (including header)\n",
    "for file in $(hdfs dfs -ls $genre_dir | grep .tsv | awk '{print $8}')\n",
    "do\n",
    "  # Get the number of rows in the current file\n",
    "  row_count=$(hdfs dfs -cat $file | wc -l)\n",
    "  \n",
    "  # Add the row count to the total\n",
    "  total_rows=$((total_rows + row_count))\n",
    "  \n",
    "  # Print the row count for each file (optional)\n",
    "  echo \"File: $file, Rows: $row_count\"\n",
    "done\n",
    "\n",
    "# Print the total number of rows\n",
    "echo \"Total Row Count for Genre Directory: $total_rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Counting Rows for the Statistic Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows for each of file in the statistic and save as csv\n",
    "!for i in `hdfs dfs -ls -R /data/msd/audio/statistics | awk '{print $8}'`; do echo $i ; \\\n",
    "hdfs dfs -cat $i | zcat | wc -l; done > statistics_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Row Count for Statistics Subdirectories: 992866\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Define the HDFS path for the statistics file\n",
    "statistics_file=\"hdfs:///data/msd/audio/statistics/sample_properties.csv.gz\"\n",
    "\n",
    "# Count the number of rows (including header) in the compressed file, and redirect errors to /dev/null\n",
    "row_count=$(hdfs dfs -cat $statistics_file 2>/dev/null | gunzip | wc -l)\n",
    "\n",
    "# Print the total number of rows\n",
    "echo \"Total Row Count for Statistics Subdirectories: $row_count\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Counting Rows for the Main Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows for each of file in the statistic and save as csv\n",
    "!for i in `hdfs dfs -ls -R /data/msd/main/summary | awk '{print $8}'`; do echo $i ; \\\n",
    "hdfs dfs -cat $i | zcat | wc -l; done > main_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /data/msd/main/summary/analysis.csv.gz, Rows: 1000001\n",
      "File: /data/msd/main/summary/metadata.csv.gz, Rows: 1000001\n",
      "Total Row Count for Main Directory: 2000002\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Define the HDFS path for the summary directory in main\n",
    "summary_dir=\"/data/msd/main/summary\"\n",
    "\n",
    "# Initialize a variable to store the total row count\n",
    "total_rows=0\n",
    "\n",
    "# Loop through each .csv.gz file in the summary directory and count the rows (including header)\n",
    "for file in $(hdfs dfs -ls $summary_dir | grep .gz | awk '{print $8}')\n",
    "do\n",
    "  # Get the number of rows in the current compressed file\n",
    "  row_count=$(hdfs dfs -cat $file | gunzip | wc -l)\n",
    "  \n",
    "  # Add the row count to the total\n",
    "  total_rows=$((total_rows + row_count))\n",
    "  \n",
    "  # Print the row count for each file (optional)\n",
    "  echo \"File: $file, Rows: $row_count\"\n",
    "done\n",
    "\n",
    "# Print the total number of rows\n",
    "echo \"Total Row Count for Main Directory: $total_rows\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Counting Rows for the Tasteprofile Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows for each of file in the triplets and save as csv\n",
    "!for i in `hdfs dfs -ls -R /data/msd/tasteprofile/triplets.tsv | awk '{print $8}'`; do echo $i ; \\\n",
    "hdfs dfs -cat $i | zcat | wc -l; done > triplets_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rwxr-xr-x   8 jsw93 supergroup      91342 2021-09-29 10:35 /data/msd/tasteprofile/mismatches/sid_matches_manually_accepted.txt\r\n",
      "-rwxr-xr-x   8 jsw93 supergroup    2026182 2021-09-29 10:35 /data/msd/tasteprofile/mismatches/sid_mismatches.txt\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /data/msd/tasteprofile/mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the rows for each of file in the missmatches and save as csv\n",
    "!for i in `hdfs dfs -ls /data/msd/tasteprofile/mismatches | grep '.txt$' | awk '{print $8}'`; do \\\n",
    "  echo \"$(basename $i),$(hdfs dfs -cat $i | wc -l)\"; done > mismatches_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /data/msd/tasteprofile/mismatches/sid_matches_manually_accepted.txt, Rows: 938\n",
      "File: /data/msd/tasteprofile/mismatches/sid_mismatches.txt, Rows: 19094\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00000.tsv.gz, Rows: 6050000\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00001.tsv.gz, Rows: 6050000\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00002.tsv.gz, Rows: 6050000\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00003.tsv.gz, Rows: 6050000\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00004.tsv.gz, Rows: 6050000\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00005.tsv.gz, Rows: 6050000\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00006.tsv.gz, Rows: 6050000\n",
      "File: /data/msd/tasteprofile/triplets.tsv/part-00007.tsv.gz, Rows: 6023586\n",
      "Total Row Count for TasteProfile Directory: 48393618\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "# Define the HDFS paths for the tasteprofile directories\n",
    "mismatches_dir=\"/data/msd/tasteprofile/mismatches\"\n",
    "triplets_dir=\"/data/msd/tasteprofile/triplets.tsv\"\n",
    "\n",
    "# Initialize a variable to store the total row count\n",
    "total_rows=0\n",
    "\n",
    "# Count rows for mismatches (.txt files)\n",
    "for file in $(hdfs dfs -ls $mismatches_dir | grep .txt | awk '{print $8}')\n",
    "do\n",
    "  # Get the number of rows in the current .txt file\n",
    "  row_count=$(hdfs dfs -cat $file | wc -l)\n",
    "  \n",
    "  # Add the row count to the total\n",
    "  total_rows=$((total_rows + row_count))\n",
    "  \n",
    "  # Print the row count for each file (optional)\n",
    "  echo \"File: $file, Rows: $row_count\"\n",
    "done\n",
    "\n",
    "# Count rows for triplets (.tsv.gz files)\n",
    "for file in $(hdfs dfs -ls $triplets_dir | grep .gz | awk '{print $8}')\n",
    "do\n",
    "  # Get the number of rows in the current compressed .tsv.gz file\n",
    "  row_count=$(hdfs dfs -cat $file | gunzip | wc -l)\n",
    "  \n",
    "  # Add the row count to the total\n",
    "  total_rows=$((total_rows + row_count))\n",
    "  \n",
    "  # Print the row count for each file (optional)\n",
    "  echo \"File: $file, Rows: $row_count\"\n",
    "done\n",
    "\n",
    "# Print the total number of rows\n",
    "echo \"Total Row Count for TasteProfile Directory: $total_rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell before closing the notebook or kill your spark application by hand using the link in the Spark UI\n",
    "\n",
    "stop_spark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
