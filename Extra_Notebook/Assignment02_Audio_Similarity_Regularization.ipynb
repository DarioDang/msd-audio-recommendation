{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }table.dataframe td { white-space: nowrap !important; }table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to import pyspark and to define start_spark() and stop_spark()\n",
    "\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import random\n",
    "import re\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Functions used below\n",
    "\n",
    "def username():\n",
    "    \"\"\"Get username with any domain information removed.\n",
    "    \"\"\"\n",
    "\n",
    "    return re.sub('@.*', '', getpass.getuser())\n",
    "\n",
    "\n",
    "def dict_to_html(d):\n",
    "    \"\"\"Convert a Python dictionary into a two column table for display.\n",
    "    \"\"\"\n",
    "\n",
    "    html = []\n",
    "\n",
    "    html.append(f'<table width=\"100%\" style=\"width:100%; font-family: monospace;\">')\n",
    "    for k, v in d.items():\n",
    "        html.append(f'<tr><td style=\"text-align:left;\">{k}</td><td>{v}</td></tr>')\n",
    "    html.append(f'</table>')\n",
    "\n",
    "    return ''.join(html)\n",
    "\n",
    "\n",
    "def show_as_html(df, n=10):\n",
    "    \"\"\"Leverage existing pandas jupyter integration to show a spark dataframe as html.\n",
    "    \n",
    "    Args:\n",
    "        n (int): number of rows to show (default: 20)\n",
    "    \"\"\"\n",
    "\n",
    "    display(df.limit(n).toPandas())\n",
    "\n",
    "    \n",
    "def display_spark():\n",
    "    \"\"\"Display the status of the active Spark session if one is currently running.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        name = sc.getConf().get(\"spark.app.name\")\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>{name}</code> under the running applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'<li><a href=\"{sc.uiWebUrl}\" target=\"_blank\">Spark Application UI</a></li>',\n",
    "            f'</ul>',\n",
    "            f'<p><b>Config</b></p>',\n",
    "            dict_to_html(dict(sc.getConf().getAll())),\n",
    "            f'<p><b>Notes</b></p>',\n",
    "            f'<ul>',\n",
    "            f'<li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li>',\n",
    "            f'<li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>{name}</code> by hand using the link in the Spark UI.</li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        html = [\n",
    "            f'<p><b>Spark</b></p>',\n",
    "            f'<p>The spark session is <b><span style=\"color:red\">stopped</span></b>, confirm that <code>{username() + \" (jupyter)\"}</code> is under the completed applications section in the Spark UI.</p>',\n",
    "            f'<ul>',\n",
    "            f'<li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li>',\n",
    "            f'</ul>',\n",
    "        ]\n",
    "        display(HTML(''.join(html)))\n",
    "\n",
    "\n",
    "# Functions to start and stop spark\n",
    "\n",
    "def start_spark(executor_instances=2, executor_cores=1, worker_memory=1, master_memory=1):\n",
    "    \"\"\"Start a new Spark session and define globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \n",
    "    Args:\n",
    "        executor_instances (int): number of executors (default: 2)\n",
    "        executor_cores (int): number of cores per executor (default: 1)\n",
    "        worker_memory (float): worker memory (default: 1)\n",
    "        master_memory (float): master memory (default: 1)\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    user = username()\n",
    "    \n",
    "    cores = executor_instances * executor_cores\n",
    "    partitions = cores * 4\n",
    "    port = 4000 + random.randint(1, 999)\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .master(\"spark://masternode2:7077\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", f\"-Dderby.system.home=/tmp/{user}/spark/\")\n",
    "        .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "        .config(\"spark.executor.instances\", str(executor_instances))\n",
    "        .config(\"spark.executor.cores\", str(executor_cores))\n",
    "        .config(\"spark.cores.max\", str(cores))\n",
    "        .config(\"spark.executor.memory\", f\"{worker_memory}g\")\n",
    "        .config(\"spark.driver.memory\", f\"{master_memory}g\")\n",
    "        .config(\"spark.driver.maxResultSize\", \"0\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", str(partitions))\n",
    "        .config(\"spark.ui.port\", str(port))\n",
    "        .appName(user + \" (jupyter)\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    \n",
    "    display_spark()\n",
    "\n",
    "    \n",
    "def stop_spark():\n",
    "    \"\"\"Stop the active Spark session and delete globals for SparkSession (spark) and SparkContext (sc).\n",
    "    \"\"\"\n",
    "\n",
    "    global spark\n",
    "    global sc\n",
    "\n",
    "    if 'spark' in globals() and 'sc' in globals():\n",
    "\n",
    "        spark.stop()\n",
    "\n",
    "        del spark\n",
    "        del sc\n",
    "\n",
    "    display_spark()\n",
    "\n",
    "\n",
    "# Make css changes to improve spark output readability\n",
    "\n",
    "html = [\n",
    "    '<style>',\n",
    "    'pre { white-space: pre !important; }',\n",
    "    'table.dataframe td { white-space: nowrap !important; }',\n",
    "    'table.dataframe thead th:first-child, table.dataframe tbody th { display: none; }',\n",
    "    '</style>',\n",
    "]\n",
    "display(HTML(''.join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def show_class_balance(data, name=\"data\", labelCol=\"label\"):\n",
    "    \"\"\"Helper function to show class balance based on label.\n",
    "    \n",
    "    Note that this function does not return anything.\n",
    "\n",
    "    Args:\n",
    "        data (pyspark.sql.DataFrame): datafame with label\n",
    "        name (str): name to print above metrics for readability \n",
    "        labelCol (str): label column name\n",
    "    \"\"\"\n",
    "\n",
    "    total = data.count()\n",
    "    counts = data.groupBy(labelCol).count().toPandas()\n",
    "    counts[\"ratio\"] = counts[\"count\"] / total\n",
    "\n",
    "    print(f'Class balance [{name}]')\n",
    "    print(f'')\n",
    "    print(f'total:   {total}')\n",
    "    print(f'counts:')\n",
    "    print(counts)\n",
    "    print(f'')\n",
    "\n",
    "def with_custom_prediction(\n",
    "    pred,\n",
    "    threshold,\n",
    "    probabilityCol=\"probability\",\n",
    "    customPredictionCol=\"customPrediction\",\n",
    "):\n",
    "    \"\"\"Helper function to select a custom prediction column for a custom classification threshold.\n",
    "    \n",
    "    Args:\n",
    "        pred (pyspark.sql.DataFrame): datafame with column for probability \n",
    "        threshold (float): classification threshold\n",
    "        probabilityCol (str): probability column name\n",
    "        customPredictionCol (str): new custom prediction column name\n",
    "    \n",
    "    Returns:\n",
    "        pred (pyspark.sql.DataFrame): dataframe with new colum for custom prediction\n",
    "    \"\"\"\n",
    "\n",
    "    classification_udf = F.udf(lambda x: int(x[1] > threshold), IntegerType())\n",
    "    \n",
    "    return pred.withColumn(customPredictionCol, classification_udf(F.col(probabilityCol)))\n",
    "\n",
    "\n",
    "def show_metrics(\n",
    "    pred,\n",
    "    name=\"data\",\n",
    "    threshold=0.5,\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "):\n",
    "    \"\"\"Helper function to evaluate and show metrics based on a custom classification threshold.\n",
    "    \n",
    "    Note that this function does not return anything.\n",
    "    \n",
    "    Args:\n",
    "        pred (pyspark.sql.DataFrame): datafame with column for probability \n",
    "        name (str): name to print above metrics for readability \n",
    "        threshold (float): classification threshold (default: 0.5)\n",
    "        predictionCol (str): prediction column name\n",
    "        rawPredictionCol (str): raw prediction column name\n",
    "        probabilityCol (str): probability column name\n",
    "    \"\"\"\n",
    "\n",
    "    if threshold != 0.5:\n",
    "\n",
    "        predictionCol = \"customPrediction\"\n",
    "        pred = with_custom_prediction(pred, threshold, probabilityCol=probabilityCol, customPredictionCol=predictionCol)\n",
    "\n",
    "    total = pred.count()\n",
    "\n",
    "    nP_actual = pred.filter((F.col(labelCol) == 1)).count()\n",
    "    nN_actual = pred.filter((F.col(labelCol) == 0)).count()\n",
    "\n",
    "    nP = pred.filter((F.col(predictionCol) == 1)).count()\n",
    "    nN = pred.filter((F.col(predictionCol) == 0)).count()\n",
    "    TP = pred.filter((F.col(predictionCol) == 1) & (F.col(labelCol) == 1)).count()\n",
    "    FP = pred.filter((F.col(predictionCol) == 1) & (F.col(labelCol) == 0)).count()\n",
    "    FN = pred.filter((F.col(predictionCol) == 0) & (F.col(labelCol) == 1)).count()\n",
    "    TN = pred.filter((F.col(predictionCol) == 0) & (F.col(labelCol) == 0)).count()\n",
    "\n",
    "    if TP + FP > 0:\n",
    "        precision = TP / (TP + FP)\n",
    "    else:\n",
    "        precision = 0\n",
    "        \n",
    "    recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / total\n",
    "\n",
    "    binary_evaluator = BinaryClassificationEvaluator(\n",
    "        rawPredictionCol=rawPredictionCol,\n",
    "        labelCol=labelCol,\n",
    "        metricName='areaUnderROC',\n",
    "    )\n",
    "    auroc = binary_evaluator.evaluate(pred)\n",
    "\n",
    "    print(f'Metrics [{name}]')\n",
    "    print(f'')\n",
    "    print(f'threshold: {threshold}')\n",
    "    print(f'')\n",
    "    print(f'total:     {total}')\n",
    "    print(f'')\n",
    "    print(f'nP actual: {nP_actual}')\n",
    "    print(f'nN actual: {nN_actual}')\n",
    "    print(f'')\n",
    "    print(f'nP:        {nP}')\n",
    "    print(f'nN:        {nN}')\n",
    "    print(f'')\n",
    "    print(f'TP         {TP}')\n",
    "    print(f'FP         {FP}')\n",
    "    print(f'FN         {FN}')\n",
    "    print(f'TN         {TN}')\n",
    "    print(f'')\n",
    "    print(f'precision: {precision:.8f}')\n",
    "    print(f'recall:    {recall:.8f}')\n",
    "    print(f'accuracy:  {accuracy:.8f}')\n",
    "    print(f'')\n",
    "    print(f'auroc:     {auroc:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>Spark</b></p><p>The spark session is <b><span style=\"color:green\">active</span></b>, look for <code>kda115 (jupyter)</code> under the running applications section in the Spark UI.</p><ul><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:4036\" target=\"_blank\">Spark Application UI</a></li></ul><p><b>Config</b></p><table width=\"100%\" style=\"width:100%; font-family: monospace;\"><tr><td style=\"text-align:left;\">spark.app.name</td><td>kda115 (jupyter)</td></tr><tr><td style=\"text-align:left;\">spark.dynamicAllocation.enabled</td><td>false</td></tr><tr><td style=\"text-align:left;\">spark.executor.instances</td><td>4</td></tr><tr><td style=\"text-align:left;\">spark.sql.warehouse.dir</td><td>file:/users/home/kda115/Assignment%2002/Assignment_Notebook/Analysis/spark-warehouse</td></tr><tr><td style=\"text-align:left;\">spark.driver.port</td><td>36787</td></tr><tr><td style=\"text-align:left;\">spark.master</td><td>spark://masternode2:7077</td></tr><tr><td style=\"text-align:left;\">spark.executor.id</td><td>driver</td></tr><tr><td style=\"text-align:left;\">spark.driver.memory</td><td>1g</td></tr><tr><td style=\"text-align:left;\">spark.driver.host</td><td>mathmadslinux2p.canterbury.ac.nz</td></tr><tr><td style=\"text-align:left;\">spark.sql.shuffle.partitions</td><td>16</td></tr><tr><td style=\"text-align:left;\">spark.cores.max</td><td>4</td></tr><tr><td style=\"text-align:left;\">spark.app.startTime</td><td>1729586142819</td></tr><tr><td style=\"text-align:left;\">spark.executor.memory</td><td>1g</td></tr><tr><td style=\"text-align:left;\">spark.rdd.compress</td><td>True</td></tr><tr><td style=\"text-align:left;\">spark.serializer.objectStreamReset</td><td>100</td></tr><tr><td style=\"text-align:left;\">spark.driver.maxResultSize</td><td>0</td></tr><tr><td style=\"text-align:left;\">spark.submit.pyFiles</td><td></td></tr><tr><td style=\"text-align:left;\">spark.ui.port</td><td>4036</td></tr><tr><td style=\"text-align:left;\">spark.executor.cores</td><td>1</td></tr><tr><td style=\"text-align:left;\">spark.submit.deployMode</td><td>client</td></tr><tr><td style=\"text-align:left;\">spark.driver.extraJavaOptions</td><td>-Dderby.system.home=/tmp/kda115/spark/</td></tr><tr><td style=\"text-align:left;\">spark.app.id</td><td>app-20241022213543-0391</td></tr><tr><td style=\"text-align:left;\">spark.ui.showConsoleProgress</td><td>true</td></tr></table><p><b>Notes</b></p><ul><li>The spark session <code>spark</code> and spark context <code>sc</code> global variables have been defined by <code>start_spark()</code>.</li><li>Please run <code>stop_spark()</code> before closing the notebook or restarting the kernel or kill <code>kda115 (jupyter)</code> by hand using the link in the Spark UI.</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to start a spark session in this notebook\n",
    "\n",
    "start_spark(executor_instances=4, executor_cores=2, worker_memory=2, master_memory=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your imports and code here or insert cells below\n",
    "\n",
    "from pyspark.sql import Row, DataFrame, Window, functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.classification import OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RankingEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other imports to be used locally\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(edgeitems=5, threshold=100, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AMM_std_1: double (nullable = true)\n",
      " |-- AMM_std_2: double (nullable = true)\n",
      " |-- AMM_std_3: double (nullable = true)\n",
      " |-- AMM_std_4: double (nullable = true)\n",
      " |-- AMM_std_5: double (nullable = true)\n",
      " |-- AMM_std_6: double (nullable = true)\n",
      " |-- AMM_std_7: double (nullable = true)\n",
      " |-- AMM_std_8: double (nullable = true)\n",
      " |-- AMM_std_9: double (nullable = true)\n",
      " |-- AMM_std_10: double (nullable = true)\n",
      " |-- AMM_avg_1: double (nullable = true)\n",
      " |-- AMM_avg_2: double (nullable = true)\n",
      " |-- AMM_avg_3: double (nullable = true)\n",
      " |-- AMM_avg_4: double (nullable = true)\n",
      " |-- AMM_avg_5: double (nullable = true)\n",
      " |-- AMM_avg_6: double (nullable = true)\n",
      " |-- AMM_avg_7: double (nullable = true)\n",
      " |-- AMM_avg_8: double (nullable = true)\n",
      " |-- AMM_avg_9: double (nullable = true)\n",
      " |-- AMM_avg_10: double (nullable = true)\n",
      " |-- msd_track_id: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMM_std_1</th>\n",
       "      <th>AMM_std_2</th>\n",
       "      <th>AMM_std_3</th>\n",
       "      <th>AMM_std_4</th>\n",
       "      <th>AMM_std_5</th>\n",
       "      <th>AMM_std_6</th>\n",
       "      <th>AMM_std_7</th>\n",
       "      <th>AMM_std_8</th>\n",
       "      <th>AMM_std_9</th>\n",
       "      <th>AMM_std_10</th>\n",
       "      <th>...</th>\n",
       "      <th>AMM_avg_3</th>\n",
       "      <th>AMM_avg_4</th>\n",
       "      <th>AMM_avg_5</th>\n",
       "      <th>AMM_avg_6</th>\n",
       "      <th>AMM_avg_7</th>\n",
       "      <th>AMM_avg_8</th>\n",
       "      <th>AMM_avg_9</th>\n",
       "      <th>AMM_avg_10</th>\n",
       "      <th>msd_track_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3530</td>\n",
       "      <td>6709.0</td>\n",
       "      <td>34770.0</td>\n",
       "      <td>160500000.0</td>\n",
       "      <td>8.346000e+08</td>\n",
       "      <td>4.339000e+09</td>\n",
       "      <td>7.075000e+12</td>\n",
       "      <td>7.494000e+09</td>\n",
       "      <td>3.898000e+10</td>\n",
       "      <td>9.937000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>60010.0</td>\n",
       "      <td>-179000000.0</td>\n",
       "      <td>-9.277000e+08</td>\n",
       "      <td>-4.805000e+09</td>\n",
       "      <td>6.227000e+12</td>\n",
       "      <td>8.320000e+09</td>\n",
       "      <td>4.312000e+10</td>\n",
       "      <td>8.685000e+14</td>\n",
       "      <td>TROVQKM128F9316E59</td>\n",
       "      <td>Pop_Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4280</td>\n",
       "      <td>6712.0</td>\n",
       "      <td>48250.0</td>\n",
       "      <td>160600000.0</td>\n",
       "      <td>1.129000e+09</td>\n",
       "      <td>7.922000e+09</td>\n",
       "      <td>7.085000e+12</td>\n",
       "      <td>1.015000e+10</td>\n",
       "      <td>7.123000e+10</td>\n",
       "      <td>2.433000e+15</td>\n",
       "      <td>...</td>\n",
       "      <td>77860.0</td>\n",
       "      <td>-179200000.0</td>\n",
       "      <td>-1.225000e+09</td>\n",
       "      <td>-8.383000e+09</td>\n",
       "      <td>6.239000e+12</td>\n",
       "      <td>1.101000e+10</td>\n",
       "      <td>7.533000e+10</td>\n",
       "      <td>2.044000e+15</td>\n",
       "      <td>TROVQAK128E0781B79</td>\n",
       "      <td>Pop_Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.6200</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>30780.0</td>\n",
       "      <td>39940000.0</td>\n",
       "      <td>3.666000e+08</td>\n",
       "      <td>3.363000e+09</td>\n",
       "      <td>8.782000e+11</td>\n",
       "      <td>3.293000e+09</td>\n",
       "      <td>3.022000e+10</td>\n",
       "      <td>6.773000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>52720.0</td>\n",
       "      <td>-44450000.0</td>\n",
       "      <td>-4.070000e+08</td>\n",
       "      <td>-3.722000e+09</td>\n",
       "      <td>7.715000e+11</td>\n",
       "      <td>3.648000e+09</td>\n",
       "      <td>3.340000e+10</td>\n",
       "      <td>5.925000e+14</td>\n",
       "      <td>TROVQSD128F42283D2</td>\n",
       "      <td>Pop_Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0700</td>\n",
       "      <td>3354.0</td>\n",
       "      <td>23280.0</td>\n",
       "      <td>39960000.0</td>\n",
       "      <td>2.804000e+08</td>\n",
       "      <td>1.965000e+09</td>\n",
       "      <td>8.790000e+11</td>\n",
       "      <td>2.515000e+09</td>\n",
       "      <td>1.764000e+10</td>\n",
       "      <td>3.042000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>40850.0</td>\n",
       "      <td>-44490000.0</td>\n",
       "      <td>-3.135000e+08</td>\n",
       "      <td>-2.207000e+09</td>\n",
       "      <td>7.723000e+11</td>\n",
       "      <td>2.807000e+09</td>\n",
       "      <td>1.978000e+10</td>\n",
       "      <td>2.687000e+14</td>\n",
       "      <td>TROVQBK128F42992E8</td>\n",
       "      <td>Pop_Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5706</td>\n",
       "      <td>6727.0</td>\n",
       "      <td>31660.0</td>\n",
       "      <td>161300000.0</td>\n",
       "      <td>7.530000e+08</td>\n",
       "      <td>3.516000e+09</td>\n",
       "      <td>7.132000e+12</td>\n",
       "      <td>6.693000e+09</td>\n",
       "      <td>3.127000e+10</td>\n",
       "      <td>7.161000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>53980.0</td>\n",
       "      <td>-179900000.0</td>\n",
       "      <td>-8.392000e+08</td>\n",
       "      <td>-3.910000e+09</td>\n",
       "      <td>6.278000e+12</td>\n",
       "      <td>7.451000e+09</td>\n",
       "      <td>3.476000e+10</td>\n",
       "      <td>6.377000e+14</td>\n",
       "      <td>TROVQFG128F92CD6DC</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMM_std_1  AMM_std_2  AMM_std_3    AMM_std_4     AMM_std_5     AMM_std_6  \\\n",
       "0     1.3530     6709.0    34770.0  160500000.0  8.346000e+08  4.339000e+09   \n",
       "1     1.4280     6712.0    48250.0  160600000.0  1.129000e+09  7.922000e+09   \n",
       "2     1.6200     3353.0    30780.0   39940000.0  3.666000e+08  3.363000e+09   \n",
       "3     1.0700     3354.0    23280.0   39960000.0  2.804000e+08  1.965000e+09   \n",
       "4     0.5706     6727.0    31660.0  161300000.0  7.530000e+08  3.516000e+09   \n",
       "\n",
       "      AMM_std_7     AMM_std_8     AMM_std_9    AMM_std_10     ...      \\\n",
       "0  7.075000e+12  7.494000e+09  3.898000e+10  9.937000e+14     ...       \n",
       "1  7.085000e+12  1.015000e+10  7.123000e+10  2.433000e+15     ...       \n",
       "2  8.782000e+11  3.293000e+09  3.022000e+10  6.773000e+14     ...       \n",
       "3  8.790000e+11  2.515000e+09  1.764000e+10  3.042000e+14     ...       \n",
       "4  7.132000e+12  6.693000e+09  3.127000e+10  7.161000e+14     ...       \n",
       "\n",
       "   AMM_avg_3    AMM_avg_4     AMM_avg_5     AMM_avg_6     AMM_avg_7  \\\n",
       "0    60010.0 -179000000.0 -9.277000e+08 -4.805000e+09  6.227000e+12   \n",
       "1    77860.0 -179200000.0 -1.225000e+09 -8.383000e+09  6.239000e+12   \n",
       "2    52720.0  -44450000.0 -4.070000e+08 -3.722000e+09  7.715000e+11   \n",
       "3    40850.0  -44490000.0 -3.135000e+08 -2.207000e+09  7.723000e+11   \n",
       "4    53980.0 -179900000.0 -8.392000e+08 -3.910000e+09  6.278000e+12   \n",
       "\n",
       "      AMM_avg_8     AMM_avg_9    AMM_avg_10        msd_track_id       genre  \n",
       "0  8.320000e+09  4.312000e+10  8.685000e+14  TROVQKM128F9316E59    Pop_Rock  \n",
       "1  1.101000e+10  7.533000e+10  2.044000e+15  TROVQAK128E0781B79    Pop_Rock  \n",
       "2  3.648000e+09  3.340000e+10  5.925000e+14  TROVQSD128F42283D2    Pop_Rock  \n",
       "3  2.807000e+09  1.978000e+10  2.687000e+14  TROVQBK128F42992E8    Pop_Rock  \n",
       "4  7.451000e+09  3.476000e+10  6.377000e+14  TROVQFG128F92CD6DC  Electronic  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the songs_with_genre parquet file back into a Spark DataFrame\n",
    "songs_with_genre = spark.read.parquet('hdfs:///user/kda115/Assignment02/data/songs_with_genre.parquet')\n",
    "\n",
    "# Show the result\n",
    "songs_with_genre.printSchema()\n",
    "show_as_html(songs_with_genre,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Similarity Binary Classification Using Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Convert the genre column into a new binary label that represent if the track is \"Electronic\" or some other genre \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMM_std_1</th>\n",
       "      <th>AMM_std_2</th>\n",
       "      <th>AMM_std_3</th>\n",
       "      <th>AMM_std_4</th>\n",
       "      <th>AMM_std_5</th>\n",
       "      <th>AMM_std_6</th>\n",
       "      <th>AMM_std_7</th>\n",
       "      <th>AMM_std_8</th>\n",
       "      <th>AMM_std_9</th>\n",
       "      <th>AMM_std_10</th>\n",
       "      <th>...</th>\n",
       "      <th>AMM_avg_4</th>\n",
       "      <th>AMM_avg_5</th>\n",
       "      <th>AMM_avg_6</th>\n",
       "      <th>AMM_avg_7</th>\n",
       "      <th>AMM_avg_8</th>\n",
       "      <th>AMM_avg_9</th>\n",
       "      <th>AMM_avg_10</th>\n",
       "      <th>msd_track_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3530</td>\n",
       "      <td>6709.0</td>\n",
       "      <td>34770.0</td>\n",
       "      <td>160500000.0</td>\n",
       "      <td>8.346000e+08</td>\n",
       "      <td>4.339000e+09</td>\n",
       "      <td>7.075000e+12</td>\n",
       "      <td>7.494000e+09</td>\n",
       "      <td>3.898000e+10</td>\n",
       "      <td>9.937000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>-179000000.0</td>\n",
       "      <td>-9.277000e+08</td>\n",
       "      <td>-4.805000e+09</td>\n",
       "      <td>6.227000e+12</td>\n",
       "      <td>8.320000e+09</td>\n",
       "      <td>4.312000e+10</td>\n",
       "      <td>8.685000e+14</td>\n",
       "      <td>TROVQKM128F9316E59</td>\n",
       "      <td>Pop_Rock</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4280</td>\n",
       "      <td>6712.0</td>\n",
       "      <td>48250.0</td>\n",
       "      <td>160600000.0</td>\n",
       "      <td>1.129000e+09</td>\n",
       "      <td>7.922000e+09</td>\n",
       "      <td>7.085000e+12</td>\n",
       "      <td>1.015000e+10</td>\n",
       "      <td>7.123000e+10</td>\n",
       "      <td>2.433000e+15</td>\n",
       "      <td>...</td>\n",
       "      <td>-179200000.0</td>\n",
       "      <td>-1.225000e+09</td>\n",
       "      <td>-8.383000e+09</td>\n",
       "      <td>6.239000e+12</td>\n",
       "      <td>1.101000e+10</td>\n",
       "      <td>7.533000e+10</td>\n",
       "      <td>2.044000e+15</td>\n",
       "      <td>TROVQAK128E0781B79</td>\n",
       "      <td>Pop_Rock</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.6200</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>30780.0</td>\n",
       "      <td>39940000.0</td>\n",
       "      <td>3.666000e+08</td>\n",
       "      <td>3.363000e+09</td>\n",
       "      <td>8.782000e+11</td>\n",
       "      <td>3.293000e+09</td>\n",
       "      <td>3.022000e+10</td>\n",
       "      <td>6.773000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>-44450000.0</td>\n",
       "      <td>-4.070000e+08</td>\n",
       "      <td>-3.722000e+09</td>\n",
       "      <td>7.715000e+11</td>\n",
       "      <td>3.648000e+09</td>\n",
       "      <td>3.340000e+10</td>\n",
       "      <td>5.925000e+14</td>\n",
       "      <td>TROVQSD128F42283D2</td>\n",
       "      <td>Pop_Rock</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0700</td>\n",
       "      <td>3354.0</td>\n",
       "      <td>23280.0</td>\n",
       "      <td>39960000.0</td>\n",
       "      <td>2.804000e+08</td>\n",
       "      <td>1.965000e+09</td>\n",
       "      <td>8.790000e+11</td>\n",
       "      <td>2.515000e+09</td>\n",
       "      <td>1.764000e+10</td>\n",
       "      <td>3.042000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>-44490000.0</td>\n",
       "      <td>-3.135000e+08</td>\n",
       "      <td>-2.207000e+09</td>\n",
       "      <td>7.723000e+11</td>\n",
       "      <td>2.807000e+09</td>\n",
       "      <td>1.978000e+10</td>\n",
       "      <td>2.687000e+14</td>\n",
       "      <td>TROVQBK128F42992E8</td>\n",
       "      <td>Pop_Rock</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5706</td>\n",
       "      <td>6727.0</td>\n",
       "      <td>31660.0</td>\n",
       "      <td>161300000.0</td>\n",
       "      <td>7.530000e+08</td>\n",
       "      <td>3.516000e+09</td>\n",
       "      <td>7.132000e+12</td>\n",
       "      <td>6.693000e+09</td>\n",
       "      <td>3.127000e+10</td>\n",
       "      <td>7.161000e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>-179900000.0</td>\n",
       "      <td>-8.392000e+08</td>\n",
       "      <td>-3.910000e+09</td>\n",
       "      <td>6.278000e+12</td>\n",
       "      <td>7.451000e+09</td>\n",
       "      <td>3.476000e+10</td>\n",
       "      <td>6.377000e+14</td>\n",
       "      <td>TROVQFG128F92CD6DC</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMM_std_1  AMM_std_2  AMM_std_3    AMM_std_4     AMM_std_5     AMM_std_6  \\\n",
       "0     1.3530     6709.0    34770.0  160500000.0  8.346000e+08  4.339000e+09   \n",
       "1     1.4280     6712.0    48250.0  160600000.0  1.129000e+09  7.922000e+09   \n",
       "2     1.6200     3353.0    30780.0   39940000.0  3.666000e+08  3.363000e+09   \n",
       "3     1.0700     3354.0    23280.0   39960000.0  2.804000e+08  1.965000e+09   \n",
       "4     0.5706     6727.0    31660.0  161300000.0  7.530000e+08  3.516000e+09   \n",
       "\n",
       "      AMM_std_7     AMM_std_8     AMM_std_9    AMM_std_10  ...      AMM_avg_4  \\\n",
       "0  7.075000e+12  7.494000e+09  3.898000e+10  9.937000e+14  ...   -179000000.0   \n",
       "1  7.085000e+12  1.015000e+10  7.123000e+10  2.433000e+15  ...   -179200000.0   \n",
       "2  8.782000e+11  3.293000e+09  3.022000e+10  6.773000e+14  ...    -44450000.0   \n",
       "3  8.790000e+11  2.515000e+09  1.764000e+10  3.042000e+14  ...    -44490000.0   \n",
       "4  7.132000e+12  6.693000e+09  3.127000e+10  7.161000e+14  ...   -179900000.0   \n",
       "\n",
       "      AMM_avg_5     AMM_avg_6     AMM_avg_7     AMM_avg_8     AMM_avg_9  \\\n",
       "0 -9.277000e+08 -4.805000e+09  6.227000e+12  8.320000e+09  4.312000e+10   \n",
       "1 -1.225000e+09 -8.383000e+09  6.239000e+12  1.101000e+10  7.533000e+10   \n",
       "2 -4.070000e+08 -3.722000e+09  7.715000e+11  3.648000e+09  3.340000e+10   \n",
       "3 -3.135000e+08 -2.207000e+09  7.723000e+11  2.807000e+09  1.978000e+10   \n",
       "4 -8.392000e+08 -3.910000e+09  6.278000e+12  7.451000e+09  3.476000e+10   \n",
       "\n",
       "     AMM_avg_10        msd_track_id       genre  class  \n",
       "0  8.685000e+14  TROVQKM128F9316E59    Pop_Rock      0  \n",
       "1  2.044000e+15  TROVQAK128E0781B79    Pop_Rock      0  \n",
       "2  5.925000e+14  TROVQSD128F42283D2    Pop_Rock      0  \n",
       "3  2.687000e+14  TROVQBK128F42992E8    Pop_Rock      0  \n",
       "4  6.377000e+14  TROVQFG128F92CD6DC  Electronic      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the genre column into binary column \n",
    "# feature_genre_binary = feature_genre.withColumn('class', F.when(F.col('genre') == 'Electronic', 1).otherwise(0))\n",
    "songs_with_genre = songs_with_genre.withColumn(\n",
    "    'class',\n",
    "    F.when(F.col('genre') == 'Electronic',1).otherwise(0)\n",
    "    )\n",
    "\n",
    "# show the result \n",
    "show_as_html(songs_with_genre, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Split the dataset use stratified random sampling and resampling technique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.1 Stratify Random Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.353, 6709.0, 34770.0, 160500000.0, 83460000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.428, 6712.0, 48250.0, 160600000.0, 11290000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.62, 3353.0, 30780.0, 39940000.0, 366600000....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.07, 3354.0, 23280.0, 39960000.0, 280400000....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.5706, 6727.0, 31660.0, 161300000.0, 7530000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.267, 6709.0, 55000.0, 160500000.0, 13170000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.117, 3355.0, 11910.0, 40000000.0, 144400000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.8293, 6721.0, 44440.0, 161200000.0, 1067000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.608, 3358.0, 29040.0, 40090000.0, 351100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.584, 3359.0, 16990.0, 40110000.0, 202400000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      0  [1.353, 6709.0, 34770.0, 160500000.0, 83460000...\n",
       "1      0  [1.428, 6712.0, 48250.0, 160600000.0, 11290000...\n",
       "2      0  [1.62, 3353.0, 30780.0, 39940000.0, 366600000....\n",
       "3      0  [1.07, 3354.0, 23280.0, 39960000.0, 280400000....\n",
       "4      1  [0.5706, 6727.0, 31660.0, 161300000.0, 7530000...\n",
       "5      0  [1.267, 6709.0, 55000.0, 160500000.0, 13170000...\n",
       "6      0  [1.117, 3355.0, 11910.0, 40000000.0, 144400000...\n",
       "7      0  [0.8293, 6721.0, 44440.0, 161200000.0, 1067000...\n",
       "8      0  [1.608, 3358.0, 29040.0, 40090000.0, 351100000...\n",
       "9      0  [1.584, 3359.0, 16990.0, 40110000.0, 202400000..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assemble all the feature columns (those that start with \"AMM_\") into a single \"features\" vector column\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[col for col in songs_with_genre.columns if col.startswith(\"AMM_\")],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Apply the assembler to transform the dataset\n",
    "data = assembler.transform(songs_with_genre)\n",
    "\n",
    "# Select the relevant columns: label (class), and features\n",
    "data = data.select(\n",
    "    F.col('class').alias('label'),\n",
    "    F.col('features')\n",
    ")\n",
    "\n",
    "# Show the transformed data\n",
    "show_as_html(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 40662, 0: 379942}\n",
      "Class balance [data]\n",
      "\n",
      "total:   420604\n",
      "counts:\n",
      "   label   count     ratio\n",
      "0      1   40662  0.096675\n",
      "1      0  379942  0.903325\n",
      "\n",
      "Class balance [training]\n",
      "\n",
      "total:   336482\n",
      "counts:\n",
      "   label   count     ratio\n",
      "0      1   32529  0.096674\n",
      "1      0  303953  0.903326\n",
      "\n",
      "Class balance [test]\n",
      "\n",
      "total:   84122\n",
      "counts:\n",
      "   label  count     ratio\n",
      "0      1   8133  0.096681\n",
      "1      0  75989  0.903319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exact stratification using Window (multi-class, counts computed automatically)\n",
    "\n",
    "temp = (\n",
    "    data\n",
    "    .withColumn(\"id\", F.monotonically_increasing_id())\n",
    "    .withColumn(\"random\", F.rand())  # random number between 0 and 1\n",
    "    .withColumn(\n",
    "        \"row\",\n",
    "        F.row_number()  # row number in each class partition (0, 1, 2, ...)\n",
    "        .over(\n",
    "            Window\n",
    "            .partitionBy(\"label\")\n",
    "            .orderBy(\"random\")\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "counts = (\n",
    "    data\n",
    "    .groupBy(\"label\")\n",
    "    .count()\n",
    "    .toPandas()\n",
    "    .set_index(\"label\")[\"count\"]\n",
    "    .to_dict()\n",
    ")\n",
    "labels = sorted(counts.keys())\n",
    "\n",
    "print(counts)\n",
    "\n",
    "training = temp\n",
    "for label in labels:\n",
    "    training = training.where((F.col(\"label\") != label) | (F.col(\"row\") < counts[label] * 0.8))\n",
    "\n",
    "training.cache()\n",
    "\n",
    "test = temp.join(training, on=\"id\", how=\"left_anti\")\n",
    "test.cache()\n",
    "\n",
    "training = training.drop(\"id\", \"random\", \"row\")\n",
    "test = test.drop(\"id\", \"random\", \"row\")\n",
    "\n",
    "show_class_balance(data, \"data\")\n",
    "show_class_balance(training, \"training\")\n",
    "show_class_balance(test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, features: vector]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure datasets are cached\n",
    "\n",
    "data.cache()\n",
    "training.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.789, 6742.0, 68110.0, 162100000.0, 16470000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.7236, 6711.0, 47280.0, 160600000.0, 1130000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.049, 6711.0, 40170.0, 160500000.0, 96780000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.032, 6723.0, 43600.0, 161100000.0, 10510000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.324, 6721.0, 38810.0, 161000000.0, 95660000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.6975, 3316.0, 12720.0, 38950000.0, 14970000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.288, 3352.0, 20450.0, 39940000.0, 235900000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.988, 6709.0, 37240.0, 160500000.0, 89530000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.495, 6710.0, 48430.0, 160500000.0, 11700000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.786, 6755.0, 36180.0, 162700000.0, 87020000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      1  [1.789, 6742.0, 68110.0, 162100000.0, 16470000...\n",
       "1      1  [0.7236, 6711.0, 47280.0, 160600000.0, 1130000...\n",
       "2      1  [1.049, 6711.0, 40170.0, 160500000.0, 96780000...\n",
       "3      1  [1.032, 6723.0, 43600.0, 161100000.0, 10510000...\n",
       "4      1  [1.324, 6721.0, 38810.0, 161000000.0, 95660000...\n",
       "5      1  [0.6975, 3316.0, 12720.0, 38950000.0, 14970000...\n",
       "6      1  [1.288, 3352.0, 20450.0, 39940000.0, 235900000...\n",
       "7      1  [0.988, 6709.0, 37240.0, 160500000.0, 89530000...\n",
       "8      1  [1.495, 6710.0, 48430.0, 160500000.0, 11700000...\n",
       "9      1  [1.786, 6755.0, 36180.0, 162700000.0, 87020000..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_as_html(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 Resampling Method & Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2.1 No Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling for down sampling\n",
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "\n",
    "# Fit the StandardScaler model on the training data\n",
    "scaler_no_sampling = standard_scaler.fit(training)\n",
    "\n",
    "# Transform the training data\n",
    "scaled_training_nosampled = scaler_no_sampling.transform(training)\n",
    "\n",
    "# Transform the test data using the same scaler model\n",
    "scaled_nosampled_test = scaler_no_sampling.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2.1 Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance [training (downsampled)]\n",
      "\n",
      "total:   97750\n",
      "counts:\n",
      "   label  count     ratio\n",
      "0      1  32529  0.332777\n",
      "1      0  65221  0.667223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downsampling\n",
    "\n",
    "training_downsampled = (\n",
    "    training\n",
    "    .withColumn(\"random\", F.rand())\n",
    "    .where((F.col(\"label\") != 0) | ((F.col(\"label\") == 0) & (F.col(\"random\") < 2 * (40662 / 379942))))\n",
    ")\n",
    "training_downsampled.cache()\n",
    "\n",
    "show_class_balance(training_downsampled, \"training (downsampled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling DownSampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling for down sampling\n",
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "\n",
    "# Fit the StandardScaler model on the training data\n",
    "scaler_down_sampling = standard_scaler.fit(training_downsampled)\n",
    "\n",
    "# Transform the training data\n",
    "scaled_training_downsampled = scaler_down_sampling.transform(training_downsampled)\n",
    "\n",
    "# Transform the test data using the same scaler model\n",
    "scaled_downsampled_test = scaler_down_sampling.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2.2 Up Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance [training (upsampled)]\n",
      "\n",
      "total:   353769\n",
      "counts:\n",
      "   label   count     ratio\n",
      "0      1   49739  0.140597\n",
      "1      0  303953  0.859185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resampling via poisson random sampling\n",
    "\n",
    "counts = {label: count for label, count in training.groupBy(\"label\").count().collect()}\n",
    "count_lower_bound = 50000 \n",
    "#count_upper_bound = 300000\n",
    "\n",
    "def random_upsample(x, counts, count_lower_bound):\n",
    "\n",
    "    count = counts[x]\n",
    "\n",
    "    if count < count_lower_bound:\n",
    "        return [x] * int(1 + np.random.poisson((count_lower_bound - count) / count))  # randomly upsample to count_lower_bound\n",
    "    \n",
    "    return [x]  # do nothing\n",
    "\n",
    "random_upsample_udf = F.udf(lambda x: random_upsample(x, counts, count_lower_bound), ArrayType(IntegerType()))\n",
    "training_upsampled = (\n",
    "    training\n",
    "    .withColumn(\"sample\", random_upsample_udf(F.col(\"label\")))\n",
    "    .select(\n",
    "        F.col(\"label\"),\n",
    "        F.col(\"features\"),\n",
    "        F.explode(F.col(\"sample\")).alias(\"sample\")\n",
    "    )\n",
    "    .drop(\"sample\")\n",
    ")\n",
    "\n",
    "show_class_balance(training_upsampled, \"training (upsampled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling UpSampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling for up sampling\n",
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "\n",
    "# Fit the StandardScaler model on the training data\n",
    "scaler_upsampling = standard_scaler.fit(training_upsampled)\n",
    "\n",
    "# Transform the training data\n",
    "scaled_training_upsampled = scaler_upsampling.transform(training_upsampled)\n",
    "\n",
    "# Transform the test data using the same scaler model\n",
    "scaled_upsampled_test = scaler_upsampling.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2.3  ReSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance [training (resampled)]\n",
      "\n",
      "total:   182256\n",
      "counts:\n",
      "   label   count     ratio\n",
      "0      1   49921  0.273906\n",
      "1      0  131496  0.721491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resampling via poisson random sampling\n",
    "\n",
    "counts = {label: count for label, count in training.groupBy(\"label\").count().collect()}\n",
    "count_lower_bound = 50000\n",
    "count_upper_bound = 200000\n",
    "\n",
    "def random_resample(x, counts, count_lower_bound, count_upper_bound):\n",
    "\n",
    "    count = counts[x]\n",
    "\n",
    "    if count < count_lower_bound:\n",
    "        return [x] * int(1 + np.random.poisson((count_lower_bound - count) / count))  # randomly upsample to count_lower_bound\n",
    "\n",
    "    if count > count_upper_bound:\n",
    "        if np.random.rand() < count_upper_bound / count: # randomly downsample to count_upper_bound\n",
    "            return [x]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    return [x]  # do nothing\n",
    "\n",
    "random_resample_udf = F.udf(lambda x: random_resample(x, counts, count_lower_bound, count_upper_bound), ArrayType(IntegerType()))\n",
    "training_resampled = (\n",
    "    training\n",
    "    .withColumn(\"sample\", random_resample_udf(F.col(\"label\")))\n",
    "    .select(\n",
    "        F.col(\"label\"),\n",
    "        F.col(\"features\"),\n",
    "        F.explode(F.col(\"sample\")).alias(\"sample\")\n",
    "    )\n",
    "    .drop(\"sample\")\n",
    ")\n",
    "\n",
    "show_class_balance(training_resampled, \"training (resampled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling ReSampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling for re sampling\n",
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "\n",
    "# Fit the StandardScaler model on the training data\n",
    "scaler_resampling = standard_scaler.fit(training_resampled)\n",
    "\n",
    "# Transform the training data\n",
    "scaled_training_resampled = scaler_resampling.transform(training_resampled)\n",
    "\n",
    "# Transform the test data using the same scaler model\n",
    "scaled_resampled_test = scaler_resampling.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.2.4 Observation reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: integer (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- weight: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.789, 6742.0, 68110.0, 162100000.0, 16470000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.7236, 6711.0, 47280.0, 160600000.0, 1130000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.049, 6711.0, 40170.0, 160500000.0, 96780000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.032, 6723.0, 43600.0, 161100000.0, 10510000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.324, 6721.0, 38810.0, 161000000.0, 95660000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.6975, 3316.0, 12720.0, 38950000.0, 14970000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.288, 3352.0, 20450.0, 39940000.0, 235900000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.988, 6709.0, 37240.0, 160500000.0, 89530000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.495, 6710.0, 48430.0, 160500000.0, 11700000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.786, 6755.0, 36180.0, 162700000.0, 87020000...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features  weight\n",
       "0      1  [1.789, 6742.0, 68110.0, 162100000.0, 16470000...     5.0\n",
       "1      1  [0.7236, 6711.0, 47280.0, 160600000.0, 1130000...     5.0\n",
       "2      1  [1.049, 6711.0, 40170.0, 160500000.0, 96780000...     5.0\n",
       "3      1  [1.032, 6723.0, 43600.0, 161100000.0, 10510000...     5.0\n",
       "4      1  [1.324, 6721.0, 38810.0, 161000000.0, 95660000...     5.0\n",
       "5      1  [0.6975, 3316.0, 12720.0, 38950000.0, 14970000...     5.0\n",
       "6      1  [1.288, 3352.0, 20450.0, 39940000.0, 235900000...     5.0\n",
       "7      1  [0.988, 6709.0, 37240.0, 160500000.0, 89530000...     5.0\n",
       "8      1  [1.495, 6710.0, 48430.0, 160500000.0, 11700000...     5.0\n",
       "9      1  [1.786, 6755.0, 36180.0, 162700000.0, 87020000...     5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label weights\n",
      "0      1   [5.0]\n",
      "1      0   [1.0]\n"
     ]
    }
   ],
   "source": [
    "# Observation reweighting\n",
    "\n",
    "training_weighted = training.withColumn(\n",
    "    \"weight\",\n",
    "    F.when(F.col(\"label\") == 0, 1.0) # when the label is 0, give 0.5 weight\n",
    "     .when(F.col(\"label\") == 1, 5.0) # when label is 1, give 5.0 weight\n",
    "     .otherwise(1.0)\n",
    ")\n",
    "\n",
    "training_weighted.printSchema()\n",
    "show_as_html(training_weighted)\n",
    "\n",
    "weights = (\n",
    "    training_weighted\n",
    "    .groupBy(\"label\")\n",
    "    .agg(\n",
    "        F.collect_set(F.col(\"weight\")).alias(\"weights\")\n",
    "    )\n",
    "    .toPandas()\n",
    ")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling Observation Reweighted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling for reweighted\n",
    "standard_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "\n",
    "# Fit the StandardScaler model on the training data\n",
    "scaler_reweighted = standard_scaler.fit(training_weighted)\n",
    "\n",
    "# Transform the training data\n",
    "scaled_training_reweighted = scaler_reweighted.transform(training_weighted)\n",
    "\n",
    "# Transform the test data using the same scaler model\n",
    "scaled_reweighted_test = scaler_reweighted.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Train and Predict each of the three classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.1 Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D.1.1 No Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics [data]\n",
      "\n",
      "threshold: 0.5\n",
      "\n",
      "total:     84122\n",
      "\n",
      "nP actual: 8133\n",
      "nN actual: 75989\n",
      "\n",
      "nP:        51\n",
      "nN:        84071\n",
      "\n",
      "TP         25\n",
      "FP         26\n",
      "FN         8108\n",
      "TN         75963\n",
      "\n",
      "precision: 0.49019608\n",
      "recall:    0.00307390\n",
      "accuracy:  0.90330710\n",
      "\n",
      "auroc:     0.60922276\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic regression model with No Sampling\n",
    "lr_no_sampling = LogisticRegression(featuresCol='features', \n",
    "                                    labelCol='label',\n",
    "                                    regParam=0.01, \n",
    "                                    elasticNetParam=1.0)\n",
    "\n",
    "lr_no_sampled_model = lr_no_sampling.fit(scaled_training_nosampled)\n",
    "\n",
    "# Predict Logistic Regression with No Sampling\n",
    "lr_no_sampled_pred = lr_no_sampled_model.transform(scaled_nosampled_test)\n",
    "lr_no_sampled_pred.cache()\n",
    "\n",
    "show_metrics(lr_no_sampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D.1.2  ReSampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics [data]\n",
      "\n",
      "threshold: 0.5\n",
      "\n",
      "total:     84122\n",
      "\n",
      "nP actual: 8133\n",
      "nN actual: 75989\n",
      "\n",
      "nP:        412\n",
      "nN:        83710\n",
      "\n",
      "TP         102\n",
      "FP         310\n",
      "FN         8031\n",
      "TN         75679\n",
      "\n",
      "precision: 0.24757282\n",
      "recall:    0.01254150\n",
      "accuracy:  0.90084639\n",
      "\n",
      "auroc:     0.61172723\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic regression model with Re Sampling 0.607\n",
    "lr_resampled = LogisticRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='label',\n",
    "    regParam=0.01, \n",
    "    elasticNetParam=1.0\n",
    ")\n",
    "lr_model_resampled = lr_resampled.fit(scaled_training_resampled)\n",
    "\n",
    "# Predict Logistic Regression with No Sampling\n",
    "lr_resampled_pred = lr_model_resampled.transform(scaled_resampled_test)\n",
    "lr_resampled_pred.cache()\n",
    "\n",
    "# Show the result\n",
    "show_metrics(lr_resampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D.1.2  UpSampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics [data]\n",
      "\n",
      "threshold: 0.5\n",
      "\n",
      "total:     84122\n",
      "\n",
      "nP actual: 8133\n",
      "nN actual: 75989\n",
      "\n",
      "nP:        168\n",
      "nN:        83954\n",
      "\n",
      "TP         62\n",
      "FP         106\n",
      "FN         8071\n",
      "TN         75883\n",
      "\n",
      "precision: 0.36904762\n",
      "recall:    0.00762326\n",
      "accuracy:  0.90279594\n",
      "\n",
      "auroc:     0.60776039\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression model with Up Sampling\n",
    "lr_upsampled = LogisticRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='label',\n",
    "    regParam=0.01, \n",
    "    elasticNetParam=1.0\n",
    ")\n",
    "lr_model_upsampled = lr_upsampled.fit(scaled_training_upsampled)\n",
    "\n",
    "# Predict Logistic Regression with No Sampling\n",
    "lr_upsampled_pred = lr_model_upsampled.transform(scaled_upsampled_test)\n",
    "lr_upsampled_pred.cache()\n",
    "\n",
    "# Show the result\n",
    "show_metrics(lr_upsampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D.1.3 Down Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics [data]\n",
      "\n",
      "threshold: 0.5\n",
      "\n",
      "total:     84122\n",
      "\n",
      "nP actual: 8133\n",
      "nN actual: 75989\n",
      "\n",
      "nP:        468\n",
      "nN:        83654\n",
      "\n",
      "TP         126\n",
      "FP         342\n",
      "FN         8007\n",
      "TN         75647\n",
      "\n",
      "precision: 0.26923077\n",
      "recall:    0.01549244\n",
      "accuracy:  0.90075129\n",
      "\n",
      "auroc:     0.61478888\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression model with Down Sampling\n",
    "lr_downsampled = LogisticRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='label',\n",
    "    regParam=0.01, \n",
    "    elasticNetParam=1.0\n",
    ")\n",
    "lr_model_downsampled = lr_downsampled.fit(scaled_training_downsampled)\n",
    "\n",
    "# Predict Logistic Regression with No Sampling\n",
    "lr_downsampled_pred = lr_model_downsampled.transform(scaled_downsampled_test)\n",
    "lr_downsampled_pred.cache()\n",
    "\n",
    "# Show the result\n",
    "show_metrics(lr_downsampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D.1.4 Observation Reweighted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics [data]\n",
      "\n",
      "threshold: 0.5\n",
      "\n",
      "total:     84122\n",
      "\n",
      "nP actual: 8133\n",
      "nN actual: 75989\n",
      "\n",
      "nP:        460\n",
      "nN:        83662\n",
      "\n",
      "TP         116\n",
      "FP         344\n",
      "FN         8017\n",
      "TN         75645\n",
      "\n",
      "precision: 0.25217391\n",
      "recall:    0.01426288\n",
      "accuracy:  0.90060864\n",
      "\n",
      "auroc:     0.61470688\n"
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression model with Observation Reweighting \n",
    "lr_reweighted = LogisticRegression(\n",
    "    featuresCol='features', \n",
    "    labelCol='label', \n",
    "    weightCol=\"weight\",\n",
    "    regParam=0.01, \n",
    "    elasticNetParam=1.0\n",
    ")\n",
    "lr_model_reweighted = lr_reweighted.fit(scaled_training_reweighted)\n",
    "\n",
    "# Predict Logistic Regression with No Sampling\n",
    "lr_reweighted_pred = lr_model_reweighted.transform(scaled_reweighted_test)\n",
    "lr_reweighted_pred.cache()\n",
    "\n",
    "# Show the result\n",
    "show_metrics(lr_reweighted_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><b>Spark</b></p><p>The spark session is <b><span style=\"color:red\">stopped</span></b>, confirm that <code>kda115 (jupyter)</code> is under the completed applications section in the Spark UI.</p><ul><li><a href=\"http://mathmadslinux2p.canterbury.ac.nz:8080/\" target=\"_blank\">Spark UI</a></li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell before closing the notebook or kill your spark application by hand using the link in the Spark UI\n",
    "\n",
    "stop_spark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
